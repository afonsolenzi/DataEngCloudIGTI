{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"spark-notations\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "from pyspark import SparkContext\n",
    "#sc= SparkContext()\n",
    "sc = SparkContext.getOrCreate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = []\n",
    "lista_arquivos = []\n",
    "input_lista_dfs = []\n",
    "\n",
    "arq_range = range(43)\n",
    "for n in arq_range:\n",
    "    if n == 0:\n",
    "        pass\n",
    "    else:\n",
    "        file = f\"microdados2017_arq{n}\"\n",
    "        df = f\"df_{n}\"\n",
    "        lista_arquivos.append(file)\n",
    "        input_lista_dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f\"C:/Lenzi/Big Data - Analytics/IGTI-BOOTCAMP/Modulo-3/Desafio-Mod3/microdados_Enade_2017_LGPD/2.DADOS/microdados2017_arq1.txt\"\n",
    "\n",
    "df = (spark.read.format(\"csv\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"delimiter\", \";\")\n",
    "        .load(csv_file))\n",
    "\n",
    "df.createOrReplaceTempView(\"df1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+----------+----------+--------+-------------+--------------+-----------+---------------+\n",
      "|NU_ANO|CO_CURSO|CO_IES|CO_CATEGAD|CO_ORGACAD|CO_GRUPO|CO_MODALIDADE|CO_MUNIC_CURSO|CO_UF_CURSO|CO_REGIAO_CURSO|\n",
      "+------+--------+------+----------+----------+--------+-------------+--------------+-----------+---------------+\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "|  2017|       3|     1|         1|     10028|    5710|            1|       5103403|         51|              5|\n",
      "+------+--------+------+----------+----------+--------+-------------+--------------+-----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|       0|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''select count(1) from df1 where CO_GRUPO= \"3201\" and CO_GRUPO= \"3202\"''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importa_enade(input_lista_dfs,lista_arquivos):   \n",
    "        \n",
    "    for df, file in zip(input_lista_dfs, lista_arquivos):\n",
    "        csv_file = f\"C:/Lenzi/Big Data - Analytics/IGTI-BOOTCAMP/Modulo-3/Desafio-Mod3/microdados_Enade_2017_LGPD/2.DADOS/microdados2017_arq1.txt\"\n",
    "        df = (spark.read.format(\"csv\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"delimiter\", \";\")\n",
    "        .load(csv_file))\n",
    "\n",
    "        final_list.append(df)\n",
    "\n",
    "    return final_list   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataFrame[NU_ANO: int, CO_CURSO: int, CO_IES: int, CO_CATEGAD: int, CO_ORGACAD: int, CO_GRUPO: int, CO_MODALIDADE: int, CO_MUNIC_CURSO: int, CO_UF_CURSO: int, CO_REGIAO_CURSO: int],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, ANO_FIM_EM: int, ANO_IN_GRAD: int, CO_TURNO_GRADUACAO: int],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, NU_ITEM_OFG: int, NU_ITEM_OFG_Z: int, NU_ITEM_OFG_X: int, NU_ITEM_OFG_N: int, NU_ITEM_OCE: int, NU_ITEM_OCE_Z: int, NU_ITEM_OCE_X: int, NU_ITEM_OCE_N: int, DS_VT_GAB_OFG_FIN: string, DS_VT_GAB_OCE_FIN: string, DS_VT_ESC_OFG: string, DS_VT_ACE_OFG: int, DS_VT_ESC_OCE: string, DS_VT_ACE_OCE: decimal(27,0), TP_PRES: int, TP_PR_GER: int, TP_PR_OB_FG: int, TP_PR_DI_FG: int, TP_PR_OB_CE: int, TP_PR_DI_CE: int, TP_SFG_D1: int, TP_SFG_D2: int, TP_SCE_D1: int, TP_SCE_D2: int, TP_SCE_D3: int, NT_GER: double, NT_FG: double, NT_OBJ_FG: double, NT_DIS_FG: double, NT_FG_D1: int, NT_FG_D1_PT: int, NT_FG_D1_CT: int, NT_FG_D2: int, NT_FG_D2_PT: int, NT_FG_D2_CT: int, NT_CE: double, NT_OBJ_CE: double, NT_DIS_CE: double, NT_CE_D1: int, NT_CE_D2: int, NT_CE_D3: int, CO_RS_I1: string, CO_RS_I2: string, CO_RS_I3: string, CO_RS_I4: string, CO_RS_I5: string, CO_RS_I6: string, CO_RS_I7: string, CO_RS_I8: string, CO_RS_I9: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I27: int, QE_I28: int, QE_I29: int, QE_I30: int, QE_I31: int, QE_I32: int, QE_I33: int, QE_I34: int, QE_I35: int, QE_I36: int, QE_I37: int, QE_I38: int, QE_I39: int, QE_I40: int, QE_I41: int, QE_I42: int, QE_I43: int, QE_I44: int, QE_I45: int, QE_I46: int, QE_I47: int, QE_I48: int, QE_I49: int, QE_I50: int, QE_I51: int, QE_I52: int, QE_I53: int, QE_I54: int, QE_I55: int, QE_I56: int, QE_I57: int, QE_I58: int, QE_I59: int, QE_I60: int, QE_I61: int, QE_I62: int, QE_I63: int, QE_I64: int, QE_I65: int, QE_I66: int, QE_I67: int, QE_I68: int],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, TP_SEXO: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, NU_IDADE: int],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I01: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I02: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I03: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I04: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I05: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I06: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I07: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I08: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I09: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I10: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I11: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I12: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I13: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I14: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I15: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I16: int],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I17: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I18: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I19: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I20: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I21: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I22: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I23: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I24: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I25: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I26: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I69: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I70: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I71: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I72: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I73: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I74: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I75: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I76: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I77: string],\n",
       " DataFrame[NU_ANO: int, CO_CURSO: int, QE_I78: string, QE_I79: string, QE_I80: string, QE_I81: string]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importa_enade( input_lista_dfs,lista_arquivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+-----------+------------------+\n",
      "|NU_ANO|CO_CURSO|ANO_FIM_EM|ANO_IN_GRAD|CO_TURNO_GRADUACAO|\n",
      "+------+--------+----------+-----------+------------------+\n",
      "|  2017|  110414|      1957|       2016|                 3|\n",
      "|  2017| 1286531|      1957|       2015|                 4|\n",
      "|  2017|  108616|      1958|       2015|                 3|\n",
      "|  2017| 1341949|      1958|       2015|                 3|\n",
      "|  2017|    9985|      1959|       2013|                 4|\n",
      "|  2017| 1160839|      1959|       2013|                 3|\n",
      "|  2017|   86672|      1960|       2006|                 4|\n",
      "|  2017|  317270|      1961|       2013|                 1|\n",
      "|  2017| 1313397|      1962|       2015|                 3|\n",
      "|  2017|   86672|      1962|       2008|                 4|\n",
      "|  2017|   52435|      1962|       2012|                 4|\n",
      "|  2017|   97851|      1962|       2007|                 1|\n",
      "|  2017|  312817|      1962|       2012|                 2|\n",
      "|  2017|   24668|      1963|       2010|                 1|\n",
      "|  2017|   99940|      1964|       2014|                 4|\n",
      "|  2017|   82854|      1964|       2012|                 4|\n",
      "|  2017| 1279416|      1964|       2014|                 4|\n",
      "|  2017|  312962|      1964|       2011|                 1|\n",
      "|  2017| 1202870|      1964|       2011|                 1|\n",
      "|  2017| 1314985|      1965|       2015|                 4|\n",
      "+------+--------+----------+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_list[1].show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = final_list[0] \n",
    "df2 = final_list[1]\n",
    "df3 = final_list[2]\n",
    "df4 = final_list[3]\n",
    "df5 = final_list[4]\n",
    "df6 = final_list[5]\n",
    "df7 = final_list[6]\n",
    "df8 = final_list[7]\n",
    "df9 = final_list[8]\n",
    "df10 = final_list[9]\n",
    "df11 = final_list[10]\n",
    "df12 = final_list[11]\n",
    "df13 = final_list[12]\n",
    "df14 = final_list[13]\n",
    "df15 = final_list[14]\n",
    "df16 = final_list[15]\n",
    "df17 = final_list[16]\n",
    "df18 = final_list[17]\n",
    "df19 = final_list[18]\n",
    "df20 = final_list[19]\n",
    "df21 = final_list[20]\n",
    "df22 = final_list[21]\n",
    "df23 = final_list[22]\n",
    "df24 = final_list[23]\n",
    "df25 = final_list[24]\n",
    "df26 = final_list[25]\n",
    "df27 = final_list[26]\n",
    "df28 = final_list[27]\n",
    "df29 = final_list[28]\n",
    "df30 = final_list[29]\n",
    "df31 = final_list[30]\n",
    "df32 = final_list[31]\n",
    "df33 = final_list[32]\n",
    "df34 = final_list[33]\n",
    "df35 = final_list[34]\n",
    "df36 = final_list[35]\n",
    "df37 = final_list[36]\n",
    "df38 = final_list[37]\n",
    "df39 = final_list[38]\n",
    "df40 = final_list[39]\n",
    "df41 = final_list[40]\n",
    "df42 = final_list[41]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(df_main, df_upd, df_main_key, df_upd_key): \n",
    "  from pyspark.sql.functions import when, lit\n",
    "  #Generates a list with the name of the columns present in the dataframe\n",
    "  df_main_cols = df_main.columns\n",
    "  df_upd_cols = df_upd.columns\n",
    "  \n",
    "  #Adds the suffix \"_tmp\" to df_upd columns\n",
    "  add_suffix = [df_upd[f'{col_name}'].alias(col_name + '_tmp') for col_name in df_upd.columns]\n",
    "  df_upd = df_upd.select(*add_suffix)\n",
    "  \n",
    "  #Doing a full outer join\n",
    "  df_join = df_main.join(df_upd, df_main[df_main_key] == df_upd[df_upd_key + '_tmp'], \"fullouter\")\n",
    "  #Using the for loop to scroll through the columns\n",
    "  for col in df_main_cols:\n",
    "      #Implementing the logic to update the rows\n",
    "      df_join = df_join.withColumn(col, when((df_main[col] != df_upd[col + '_tmp']) | (df_main[col].isNull()), df_upd[col + '_tmp']).otherwise(df_main[col]))\n",
    "  \n",
    "  #Selecting only the columns of df_main (or all columns that do not have the suffix \"_tmp\")\n",
    "  df_final = df_join.select(*df_main_cols)\n",
    "  \n",
    "  #Returns the dataframe updated with the merge\n",
    "  return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (937381330.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Lenzi\\AppData\\Local\\Temp\\ipykernel_9040\\937381330.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    ( df1[\"CO_CURSO\"] == df2[\"CO_CURSO\"]),\"inner\")\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# PySpark join multiple columns\n",
    "\n",
    "\n",
    "#globaldf = df1.join(df2, (df1[\"NU_ANO\"] == df2[\"NU_ANO\"]) &\n",
    "   ( df1[\"CO_CURSO\"] == df2[\"CO_CURSO\"]),\"inner\")\n",
    "\n",
    "#globaldf = globaldf.drop(\"df2.NU_ANO\",\"df2.CO_CURSO\")\n",
    "\n",
    "#globaldf = globaldf.join(df3, (globaldf[\"NU_ANO\"] == df3[\"NU_ANO\"]) &\n",
    "#   ( df1[\"CO_CURSO\"] == df3[\"CO_CURSO\"]),\"inner\").drop(\"df3.NU_ANO\",\"df3.CO_CURSO\")\n",
    "\n",
    "#globaldf = globaldf.join(df4, (globaldf[\"NU_ANO\"] == df4[\"NU_ANO\"]) &\n",
    "#   ( df1[\"CO_CURSO\"] == df4[\"CO_CURSO\"]),\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "537358\n",
      "537358\n"
     ]
    }
   ],
   "source": [
    "print(df1.count())\n",
    "print(df2.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468686254"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.join(df2, (\"NU_ANO\") and ( \"CO_CURSO\"),\"left\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CO_CURSO: integer (nullable = true)\n",
      " |-- NU_ANO: integer (nullable = true)\n",
      " |-- CO_IES: integer (nullable = true)\n",
      " |-- CO_CATEGAD: integer (nullable = true)\n",
      " |-- CO_ORGACAD: integer (nullable = true)\n",
      " |-- CO_GRUPO: integer (nullable = true)\n",
      " |-- CO_MODALIDADE: integer (nullable = true)\n",
      " |-- CO_MUNIC_CURSO: integer (nullable = true)\n",
      " |-- CO_UF_CURSO: integer (nullable = true)\n",
      " |-- CO_REGIAO_CURSO: integer (nullable = true)\n",
      " |-- NU_ANO: integer (nullable = true)\n",
      " |-- ANO_FIM_EM: integer (nullable = true)\n",
      " |-- ANO_IN_GRAD: integer (nullable = true)\n",
      " |-- CO_TURNO_GRADUACAO: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "globaldf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
